{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> CS 394R Final Project: Soft Actor Critic for Traffic Management</h1>\n",
    "\n",
    "William Alexander and Carlin Liao\n",
    "\n",
    "Adapted from the <a href=\"https://towardsdatascience.com/soft-actor-critic-demystified-b8427df61665\">Vaishak Kumar's Towards Data Science implementation of Soft-Actor Critic,</a> which was itself adapted from <a href=\"https://github.com/higgsfield/RL-Adventure-2\">higgsfield's implementation</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "from dta.dta_env import dta_env\n",
    "# import gym\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device   = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Auxilliary Functions</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.buffer = []\n",
    "        self.position = 0\n",
    "    \n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer.append(None)\n",
    "        self.buffer[self.position] = (state, action, reward, next_state, done)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.buffer, batch_size)\n",
    "        state, action, reward, next_state, done = map(np.stack, zip(*batch))\n",
    "        return state, action, reward, next_state, done\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NormalizedActions(gym.ActionWrapper):\n",
    "#     def _action(self, action):\n",
    "#         low  = self.action_space.low\n",
    "#         high = self.action_space.high\n",
    "        \n",
    "#         action = low + (action + 1.0) * 0.5 * (high - low)\n",
    "#         action = np.clip(action, low, high)\n",
    "        \n",
    "#         return action\n",
    "\n",
    "#     def _reverse_action(self, action):\n",
    "#         low  = self.action_space.low\n",
    "#         high = self.action_space.high\n",
    "        \n",
    "#         action = 2 * (action - low) / (high - low) - 1\n",
    "#         action = np.clip(action, low, high)\n",
    "        \n",
    "#         return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "#     plt.title('frame %s. reward: %s' % (frame_idx, rewards[-1]))\n",
    "    plt.title(f'Episode {frame_idx} reward')\n",
    "    plt.plot(rewards)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Network Definitions</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueNetwork(nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim, init_w=3e-3):\n",
    "        super(ValueNetwork, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(state_dim, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.linear3 = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "        self.linear3.weight.data.uniform_(-init_w, init_w)\n",
    "        self.linear3.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.linear1(state))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        x = x[:,0]\n",
    "        return x\n",
    "        \n",
    "        \n",
    "class SoftQNetwork(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions, hidden_size, init_w=3e-3):\n",
    "        super(SoftQNetwork, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(num_inputs + num_actions, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear3 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        self.linear3.weight.data.uniform_(-init_w, init_w)\n",
    "        self.linear3.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "    def forward(self, state, action):\n",
    "        x = torch.cat([state, action], 1)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        x = x[:,0]\n",
    "        return x\n",
    "        \n",
    "        \n",
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions, hidden_size, init_w=3e-3, log_std_min=-20, log_std_max=2):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        \n",
    "        self.log_std_min = log_std_min\n",
    "        self.log_std_max = log_std_max\n",
    "        \n",
    "        self.linear1 = nn.Linear(num_inputs, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "        self.mean_linear = nn.Linear(hidden_size, num_actions)\n",
    "        self.mean_linear.weight.data.uniform_(-init_w, init_w)\n",
    "        self.mean_linear.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "        self.log_std_linear = nn.Linear(hidden_size, num_actions)\n",
    "        self.log_std_linear.weight.data.uniform_(-init_w, init_w)\n",
    "        self.log_std_linear.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.linear1(state))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        \n",
    "        mean    = self.mean_linear(x)\n",
    "        log_std = self.log_std_linear(x)\n",
    "        log_std = torch.clamp(log_std, self.log_std_min, self.log_std_max)\n",
    "        \n",
    "        return mean, log_std\n",
    "    \n",
    "    def evaluate(self, state, epsilon=1e-6):\n",
    "        mean, log_std = self.forward(state)\n",
    "        std = log_std.exp()\n",
    "        \n",
    "        normal = Normal(0, 1)\n",
    "        z      = normal.sample()\n",
    "        action = torch.tanh(mean+ std*z.to(device))\n",
    "        log_prob = (Normal(mean, std).log_prob(mean+ std*z.to(device)) - torch.log(1 - action.pow(2) + epsilon))\n",
    "        log_prob = log_prob.sum(axis=1)\n",
    "        return action, log_prob, z, mean, log_std\n",
    "        \n",
    "    \n",
    "    def get_action(self, state):\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        mean, log_std = self.forward(state)\n",
    "        std = log_std.exp()\n",
    "        \n",
    "        normal = Normal(0, 1)\n",
    "        z      = normal.sample().to(device)\n",
    "        action = torch.tanh(mean + std*z)\n",
    "        \n",
    "        action  = action.cpu()#.detach().cpu().numpy()\n",
    "        return action[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Update Function </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(batch_size,gamma=0.99,soft_tau=1e-2,):\n",
    "    \n",
    "    state, action, reward, next_state, done = replay_buffer.sample(batch_size)\n",
    "\n",
    "    state      = torch.FloatTensor(state).to(device)\n",
    "    next_state = torch.FloatTensor(next_state).to(device)\n",
    "    action     = torch.FloatTensor(action).to(device)\n",
    "    reward     = torch.FloatTensor(reward).unsqueeze(1).to(device)\n",
    "    reward     = reward[:,0]\n",
    "    done       = torch.FloatTensor(np.float32(done)).unsqueeze(1).to(device)\n",
    "    done       = done[:,0]\n",
    "\n",
    "    predicted_q_value1 = soft_q_net1(state, action)\n",
    "    predicted_q_value2 = soft_q_net2(state, action)\n",
    "    predicted_value    = value_net(state)\n",
    "    new_action, log_prob, epsilon, mean, log_std = policy_net.evaluate(state)\n",
    "\n",
    "    \n",
    "    # Training Q Function\n",
    "    target_value = target_value_net(next_state)\n",
    "    target_q_value = reward + (1 - done) * gamma * target_value\n",
    "    q_value_loss1 = soft_q_criterion1(predicted_q_value1, target_q_value.detach())\n",
    "    q_value_loss2 = soft_q_criterion2(predicted_q_value2, target_q_value.detach())\n",
    "\n",
    "    soft_q_optimizer1.zero_grad()\n",
    "    q_value_loss1.backward()\n",
    "    soft_q_optimizer1.step()\n",
    "    soft_q_optimizer2.zero_grad()\n",
    "    q_value_loss2.backward()\n",
    "    soft_q_optimizer2.step()    \n",
    "\n",
    "    \n",
    "    # Training Value Function\n",
    "    predicted_new_q_value = torch.min(soft_q_net1(state, new_action),soft_q_net2(state, new_action))\n",
    "    target_value_func = predicted_new_q_value - log_prob\n",
    "    value_loss = value_criterion(predicted_value, target_value_func.detach())\n",
    "    \n",
    "    value_optimizer.zero_grad()\n",
    "    value_loss.backward()\n",
    "    value_optimizer.step()\n",
    "    \n",
    "\n",
    "    # Training Policy Function\n",
    "    policy_loss = (log_prob - predicted_new_q_value).mean()\n",
    "\n",
    "    policy_optimizer.zero_grad()\n",
    "    policy_loss.backward()\n",
    "    policy_optimizer.step()\n",
    "    \n",
    "    \n",
    "    # Propogate training to Target Value Function\n",
    "    for target_param, param in zip(target_value_net.parameters(), value_net.parameters()):\n",
    "        target_param.data.copy_(\n",
    "            target_param.data * (1.0 - soft_tau) + param.data * soft_tau\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Initializations </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = NormalizedActions(gym.make(\"Pendulum-v0\"))\n",
    "env = dta_env(interval=60*5, numIntervals=60//5) # interval lasts 60*5 seconds, and we run 60//5 of those for a total of 1 hour\n",
    "\n",
    "# action_dim = env.action_space.shape[0]\n",
    "# state_dim  = env.observation_space.shape[0]\n",
    "action_dim = env.action_dim\n",
    "state_dim  = env.state_dim\n",
    "hidden_dim = 256\n",
    "\n",
    "value_net        = ValueNetwork(state_dim, hidden_dim).to(device)\n",
    "target_value_net = ValueNetwork(state_dim, hidden_dim).to(device)\n",
    "\n",
    "soft_q_net1 = SoftQNetwork(state_dim, action_dim, hidden_dim).to(device)\n",
    "soft_q_net2 = SoftQNetwork(state_dim, action_dim, hidden_dim).to(device)\n",
    "policy_net = PolicyNetwork(state_dim, action_dim, hidden_dim).to(device)\n",
    "\n",
    "for target_param, param in zip(target_value_net.parameters(), value_net.parameters()):\n",
    "    target_param.data.copy_(param.data)\n",
    "    \n",
    "\n",
    "value_criterion  = nn.MSELoss()\n",
    "soft_q_criterion1 = nn.MSELoss()\n",
    "soft_q_criterion2 = nn.MSELoss()\n",
    "\n",
    "value_lr  = 3e-4\n",
    "soft_q_lr = 3e-4\n",
    "policy_lr = 3e-4\n",
    "\n",
    "value_optimizer  = optim.Adam(value_net.parameters(), lr=value_lr)\n",
    "soft_q_optimizer1 = optim.Adam(soft_q_net1.parameters(), lr=soft_q_lr)\n",
    "soft_q_optimizer2 = optim.Adam(soft_q_net2.parameters(), lr=soft_q_lr)\n",
    "policy_optimizer = optim.Adam(policy_net.parameters(), lr=policy_lr)\n",
    "\n",
    "\n",
    "replay_buffer_size = 1000000\n",
    "replay_buffer = ReplayBuffer(replay_buffer_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: tune\n",
    "episodes    = 2 #500\n",
    "time_limit  = 8*60*60\n",
    "# max_frames  = 40000\n",
    "# max_steps   = 500\n",
    "rand_eps    = 0 # number of episodes testing under random policy before switching to SAC policy\n",
    "# frame_idx   = 0\n",
    "batch_size  = 2 #128\n",
    "just_data   = False # just generate data without training the model\n",
    "use_history = False # read in observed records\n",
    "train_hist  = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_history(use_history_now=False):\n",
    "    if use_history:\n",
    "        directory = os.fsencode('observations')\n",
    "        for file in os.listdir(directory):\n",
    "            filename = os.fsdecode(file)\n",
    "            if filename.endswith(\".npy\"):\n",
    "                obs = np.load(os.path.join(directory, file), allow_pickle=True)\n",
    "                state = obs[0]\n",
    "                action = obs[1]\n",
    "                reward = obs[2]\n",
    "                next_state = obs[3]\n",
    "                done = obs[4]\n",
    "                replay_buffer.push(state, action, reward, next_state, done)\n",
    "\n",
    "                if use_history_now and len(replay_buffer) > batch_size:\n",
    "                    update(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = []\n",
    "all_steps = 0\n",
    "time_start = time.time()\n",
    "\n",
    "if use_history:\n",
    "    load_history(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for e in range(episodes):\n",
    "    state = env.reset()\n",
    "    episode_reward = 0\n",
    "    done = False\n",
    "    \n",
    "    while not done: # episodes are fixed to 1 hour / 5 min intervals = 20 steps\n",
    "        if e < rand_eps or just_data: # explore\n",
    "            action = env.random_action()\n",
    "            next_state, reward, done = env.step(action)\n",
    "        else: # use the SAC to generate a new policy\n",
    "            action = policy_net.get_action(state).detach().numpy().tolist()\n",
    "            next_state, reward, done = env.step(action)\n",
    "        \n",
    "        # prepare for next iteration \n",
    "        state = next_state\n",
    "        episode_reward += reward\n",
    "        \n",
    "        # save this observation for future use\n",
    "        replay_buffer.push(state, action, reward, next_state, done)\n",
    "        np.save(f'observations/{str(time.time())}', [state, action, reward, next_state, done])\n",
    "        \n",
    "        if not just_data: # do an update\n",
    "\n",
    "            if len(replay_buffer) > batch_size:\n",
    "                update(batch_size)\n",
    "    \n",
    "    rewards.append(episode_reward)\n",
    "\n",
    "    plot(e, rewards)\n",
    "    \n",
    "    if time.time()-time_start > time_limit:\n",
    "        break\n",
    "\n",
    "\n",
    "# while frame_idx < max_frames:\n",
    "#     state = env.reset()\n",
    "#     episode_reward = 0\n",
    "    \n",
    "#     for step in range(max_steps):\n",
    "#         if frame_idx >1000:\n",
    "#             action = policy_net.get_action(state).detach()\n",
    "#             next_state, reward, done, _ = env.step(action.numpy())\n",
    "#         else:\n",
    "#             action = env.action_space.sample()\n",
    "#             next_state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        \n",
    "#         replay_buffer.push(state, action, reward, next_state, done)\n",
    "        \n",
    "#         state = next_state\n",
    "#         episode_reward += reward\n",
    "#         frame_idx += 1\n",
    "        \n",
    "#         if len(replay_buffer) > batch_size:\n",
    "#             update(batch_size)\n",
    "        \n",
    "#         if frame_idx % 1000 == 0:\n",
    "#             plot(frame_idx, rewards)\n",
    "        \n",
    "#         if done:\n",
    "#             break\n",
    "        \n",
    "#     rewards.append(episode_reward)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
