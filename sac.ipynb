{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> CS 394R Final Project: Soft Actor Critic for Traffic Management</h1>\n",
    "\n",
    "William Alexander and Carlin Liao\n",
    "\n",
    "Adapted from the <a href=\"https://towardsdatascience.com/soft-actor-critic-demystified-b8427df61665\">Vaishak Kumar's Towards Data Science implementation of Soft-Actor Critic,</a> which was itself adapted from <a href=\"https://github.com/higgsfield/RL-Adventure-2\">higgsfield's implementation</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "from dta.dta_env import dta_env\n",
    "# import gym\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device   = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Auxilliary Functions</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.buffer = []\n",
    "        self.position = 0\n",
    "    \n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer.append(None)\n",
    "        self.buffer[self.position] = (state, action, reward, next_state, done)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.buffer, batch_size)\n",
    "        state, action, reward, next_state, done = map(np.stack, zip(*batch))\n",
    "        return state, action, reward, next_state, done\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NormalizedActions(gym.ActionWrapper):\n",
    "#     def _action(self, action):\n",
    "#         low  = self.action_space.low\n",
    "#         high = self.action_space.high\n",
    "        \n",
    "#         action = low + (action + 1.0) * 0.5 * (high - low)\n",
    "#         action = np.clip(action, low, high)\n",
    "        \n",
    "#         return action\n",
    "\n",
    "#     def _reverse_action(self, action):\n",
    "#         low  = self.action_space.low\n",
    "#         high = self.action_space.high\n",
    "        \n",
    "#         action = 2 * (action - low) / (high - low) - 1\n",
    "#         action = np.clip(action, low, high)\n",
    "        \n",
    "#         return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "#     plt.title('frame %s. reward: %s' % (frame_idx, rewards[-1]))\n",
    "    plt.title(f'Reward over {frame_idx} episodes')\n",
    "    plt.plot(rewards)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Network Definitions</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueNetwork(nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim, init_w=3e-3):\n",
    "        super(ValueNetwork, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(state_dim, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.linear3 = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "        self.linear3.weight.data.uniform_(-init_w, init_w)\n",
    "        self.linear3.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.linear1(state))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        x = x[:,0]\n",
    "        return x\n",
    "        \n",
    "        \n",
    "class SoftQNetwork(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions, hidden_size, init_w=3e-3):\n",
    "        super(SoftQNetwork, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(num_inputs + num_actions, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear3 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        self.linear3.weight.data.uniform_(-init_w, init_w)\n",
    "        self.linear3.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "    def forward(self, state, action):\n",
    "        x = torch.cat([state, action], 1)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        x = x[:,0]\n",
    "        return x\n",
    "        \n",
    "        \n",
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions, hidden_size, init_w=3e-3, log_std_min=-20, log_std_max=2):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        \n",
    "        self.log_std_min = log_std_min\n",
    "        self.log_std_max = log_std_max\n",
    "        \n",
    "        self.linear1 = nn.Linear(num_inputs, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "        self.mean_linear = nn.Linear(hidden_size, num_actions)\n",
    "        self.mean_linear.weight.data.uniform_(-init_w, init_w)\n",
    "        self.mean_linear.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "        self.log_std_linear = nn.Linear(hidden_size, num_actions)\n",
    "        self.log_std_linear.weight.data.uniform_(-init_w, init_w)\n",
    "        self.log_std_linear.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.linear1(state))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        \n",
    "        mean    = self.mean_linear(x)\n",
    "        log_std = self.log_std_linear(x)\n",
    "        log_std = torch.clamp(log_std, self.log_std_min, self.log_std_max)\n",
    "        \n",
    "        return mean, log_std\n",
    "    \n",
    "    def evaluate(self, state, epsilon=1e-6):\n",
    "        mean, log_std = self.forward(state)\n",
    "        std = log_std.exp()\n",
    "        \n",
    "        normal = Normal(0, 1)\n",
    "        z      = normal.sample()\n",
    "        action = torch.tanh(mean+ std*z.to(device))\n",
    "        log_prob = (Normal(mean, std).log_prob(mean+ std*z.to(device)) - torch.log(1 - action.pow(2) + epsilon))\n",
    "        log_prob = log_prob.sum(axis=1)\n",
    "        return action, log_prob, z, mean, log_std\n",
    "        \n",
    "    \n",
    "    def get_action(self, state):\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        mean, log_std = self.forward(state)\n",
    "        std = log_std.exp()\n",
    "        \n",
    "        normal = Normal(0, 1)\n",
    "        z      = normal.sample().to(device)\n",
    "        action = torch.tanh(mean + std*z)\n",
    "        \n",
    "        action  = action.cpu()#.detach().cpu().numpy()\n",
    "        return action[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Update Function </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(batch_size,gamma=0.99,soft_tau=1e-2,):\n",
    "    \n",
    "    state, action, reward, next_state, done = replay_buffer.sample(batch_size)\n",
    "\n",
    "    state      = torch.FloatTensor(state).to(device)\n",
    "    next_state = torch.FloatTensor(next_state).to(device)\n",
    "    action     = torch.FloatTensor(action).to(device)\n",
    "    reward     = torch.FloatTensor(reward).unsqueeze(1).to(device)\n",
    "    reward     = reward[:,0]\n",
    "    done       = torch.FloatTensor(np.float32(done)).unsqueeze(1).to(device)\n",
    "    done       = done[:,0]\n",
    "\n",
    "    predicted_q_value1 = soft_q_net1(state, action)\n",
    "    predicted_q_value2 = soft_q_net2(state, action)\n",
    "    predicted_value    = value_net(state)\n",
    "    new_action, log_prob, epsilon, mean, log_std = policy_net.evaluate(state)\n",
    "\n",
    "    \n",
    "    # Training Q Function\n",
    "    target_value = target_value_net(next_state)\n",
    "    target_q_value = reward + (1 - done) * gamma * target_value\n",
    "    q_value_loss1 = soft_q_criterion1(predicted_q_value1, target_q_value.detach())\n",
    "    q_value_loss2 = soft_q_criterion2(predicted_q_value2, target_q_value.detach())\n",
    "\n",
    "    soft_q_optimizer1.zero_grad()\n",
    "    q_value_loss1.backward()\n",
    "    soft_q_optimizer1.step()\n",
    "    soft_q_optimizer2.zero_grad()\n",
    "    q_value_loss2.backward()\n",
    "    soft_q_optimizer2.step()    \n",
    "\n",
    "    \n",
    "    # Training Value Function\n",
    "    predicted_new_q_value = torch.min(soft_q_net1(state, new_action),soft_q_net2(state, new_action))\n",
    "    target_value_func = predicted_new_q_value - log_prob\n",
    "    value_loss = value_criterion(predicted_value, target_value_func.detach())\n",
    "    \n",
    "    value_optimizer.zero_grad()\n",
    "    value_loss.backward()\n",
    "    value_optimizer.step()\n",
    "    \n",
    "\n",
    "    # Training Policy Function\n",
    "    policy_loss = (log_prob - predicted_new_q_value).mean()\n",
    "\n",
    "    policy_optimizer.zero_grad()\n",
    "    policy_loss.backward()\n",
    "    policy_optimizer.step()\n",
    "    \n",
    "    \n",
    "    # Propogate training to Target Value Function\n",
    "    for target_param, param in zip(target_value_net.parameters(), value_net.parameters()):\n",
    "        target_param.data.copy_(\n",
    "            target_param.data * (1.0 - soft_tau) + param.data * soft_tau\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: tune\n",
    "interval    = 60*5 # how long is one timestep for the DTA simulation? here it's 60*5 seconds\n",
    "n_interval  = 60//5 # how many timesteps does the DTA simulation run for? 60//5 of those for a total of 1 hour\n",
    "hidden_dim  = 64 #256 # how many nodes for each ANN's hidden layers?\n",
    "\n",
    "episodes    = 1000 #500\n",
    "time_limit  = 127*60*60 # seconds to hours\n",
    "# max_frames  = 40000\n",
    "# max_steps   = 500\n",
    "rand_eps    = 5 # number of episodes testing under random policy before switching to SAC policy\n",
    "# frame_idx   = 0\n",
    "batch_size  = 128\n",
    "just_data   = False # just generate data without training the model\n",
    "use_history = True # read in observations from past records\n",
    "train_hist  = True # train on observations from past records as they're being read in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Initializations </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = NormalizedActions(gym.make(\"Pendulum-v0\"))\n",
    "env = dta_env(interval=interval, numIntervals=n_interval)\n",
    "\n",
    "# action_dim = env.action_space.shape[0]\n",
    "# state_dim  = env.observation_space.shape[0]\n",
    "action_dim = env.action_dim\n",
    "state_dim  = env.state_dim\n",
    "# hidden_dim = 256\n",
    "\n",
    "value_net        = ValueNetwork(state_dim, hidden_dim).to(device)\n",
    "target_value_net = ValueNetwork(state_dim, hidden_dim).to(device)\n",
    "\n",
    "soft_q_net1 = SoftQNetwork(state_dim, action_dim, hidden_dim).to(device)\n",
    "soft_q_net2 = SoftQNetwork(state_dim, action_dim, hidden_dim).to(device)\n",
    "policy_net = PolicyNetwork(state_dim, action_dim, hidden_dim).to(device)\n",
    "\n",
    "for target_param, param in zip(target_value_net.parameters(), value_net.parameters()):\n",
    "    target_param.data.copy_(param.data)\n",
    "    \n",
    "\n",
    "value_criterion  = nn.MSELoss()\n",
    "soft_q_criterion1 = nn.MSELoss()\n",
    "soft_q_criterion2 = nn.MSELoss()\n",
    "\n",
    "value_lr  = 3e-4\n",
    "soft_q_lr = 3e-4\n",
    "policy_lr = 3e-4\n",
    "\n",
    "value_optimizer  = optim.Adam(value_net.parameters(), lr=value_lr)\n",
    "soft_q_optimizer1 = optim.Adam(soft_q_net1.parameters(), lr=soft_q_lr)\n",
    "soft_q_optimizer2 = optim.Adam(soft_q_net2.parameters(), lr=soft_q_lr)\n",
    "policy_optimizer = optim.Adam(policy_net.parameters(), lr=policy_lr)\n",
    "\n",
    "\n",
    "replay_buffer_size = 1000000\n",
    "replay_buffer = ReplayBuffer(replay_buffer_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_history(use_history_now=False):\n",
    "    if use_history:\n",
    "        directory = os.fsencode('observations')\n",
    "        for file in os.listdir(directory):\n",
    "            filename = os.fsdecode(file)\n",
    "            if filename.endswith(\".npy\"):\n",
    "                obs = np.load(os.path.join(directory, file), allow_pickle=True)\n",
    "                state = obs[0]\n",
    "                action = obs[1]\n",
    "                reward = obs[2]\n",
    "                next_state = obs[3]\n",
    "                done = obs[4]\n",
    "                replay_buffer.push(state, action, reward, next_state, done)\n",
    "\n",
    "                if use_history_now and len(replay_buffer) > batch_size:\n",
    "                    update(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = []\n",
    "all_steps = 0\n",
    "time_start = time.time()\n",
    "\n",
    "if use_history:\n",
    "    load_history(train_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for e in range(episodes):\n",
    "    state = env.reset()\n",
    "    episode_reward = 0\n",
    "    done = False\n",
    "    \n",
    "    while not done: # episodes are fixed to 1 hour / 5 min intervals = 20 steps\n",
    "        exploring = (e < rand_eps or just_data)\n",
    "        if exploring: # explore\n",
    "            action = env.random_action()\n",
    "            next_state, reward, done = env.step(action)\n",
    "        else: # use the SAC to generate a new policy\n",
    "            action = policy_net.get_action(state).detach().numpy().tolist()\n",
    "            next_state, reward, done = env.step(action)\n",
    "        \n",
    "        # prepare for next iteration \n",
    "        state = next_state\n",
    "        episode_reward += reward\n",
    "        \n",
    "        # save this observation for future use\n",
    "        replay_buffer.push(state, action, reward, next_state, done)\n",
    "        np.save(f'observations/{str(time.time())}' + ('_r' if exploring else ''),\n",
    "                [state, action, reward, next_state, done])\n",
    "        \n",
    "        if not just_data: # do an update\n",
    "            if len(replay_buffer) > batch_size:\n",
    "                update(batch_size)\n",
    "    \n",
    "    rewards.append(episode_reward)\n",
    "\n",
    "    plot(e, rewards)\n",
    "    \n",
    "    if time.time()-time_start > time_limit:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
